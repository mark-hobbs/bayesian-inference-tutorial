{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85181315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import scipy.stats\n",
    "\n",
    "\n",
    "# from src.material_model import LinearElasticity as LE\n",
    "# from src.sampler import MetropolisHastings, AdaptiveMetropolisHastings\n",
    "\n",
    "# from ipynb.fs.full.functions import (\n",
    "#     random_draw,\n",
    "#     linear_regression,\n",
    "#     add_labels,\n",
    "#     plot_posterior,\n",
    "#     plot_regression_results,\n",
    "# )\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Times New Roman\"],\n",
    "    }\n",
    ")\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# save_figures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcc002",
   "metadata": {},
   "source": [
    "# Linear Elasticity\n",
    "\n",
    "This example can be found in Section 5.2 in the following paper: [A Tutorial on Bayesian Inference to Identify Material Parameters in Solid Mechanics](https://doi.org/10.1007/s11831-018-09311-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfdd0e-26bd-4bb4-9881-258c9059bae0",
   "metadata": {},
   "source": [
    "## 1. Problem statement\n",
    "\n",
    "Given a series of experimental observations, obtained from a material specimen undergoing uniaxial tension - for example, stress-strain data - and acknowledging that the observations will be contaminated by a small amount of noise, infer the model parameters that describe the material response with a quantified level of uncertainty.\n",
    "\n",
    "<span style=\"color: blue;\">\n",
    "    \n",
    "We are given a series of experimental observations in the form of stress-strain ($\\sigma$-$\\epsilon$) data, obtained from a uniaxial tensile test of a linear-elastic material specimen. All observations are contaminated by a degree of noise, and it is essential to acknowledge and mitigate this noise to ensure the accuracy of any subsequent analyses or conclusions drawn from the data. \n",
    "\n",
    "</span>\n",
    "\n",
    "![](figures/linear-elastic-experimental-observations.png)\n",
    "\n",
    "<span style=\"color: blue;\">\n",
    "\n",
    "#### General problem statement\n",
    "\n",
    "Given a set of observed realisations of a random variable $X$,\n",
    "\n",
    "$$S = \\{x_1, x_2, ..., x_N\\}, \\quad x_j \\in \\mathbb{R}^n$$\n",
    " \n",
    "we aim to infer the underlying probability distributions that generate the data set $S$.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e31eee-1be5-4ec7-8bd0-e2d9d1dbb6ad",
   "metadata": {},
   "source": [
    "## 2. Material model\n",
    "\n",
    "An expert, upon examining the above experimental observations, could reasonably assume that the material response is best described by a linear elastic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef91748d-973b-4759-91d8-9cece520c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearElastic:\n",
    "    \n",
    "    def __init__(self, E):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        E : float\n",
    "            Young's Modulus\n",
    "        \"\"\"\n",
    "        self.E = E\n",
    "\n",
    "    def compute_stress(self, strain):\n",
    "        \"\"\"\n",
    "        Compute stress\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        strain : float\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        stress : float\n",
    "        \"\"\"\n",
    "        return self.E * strain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31812dde-7dd0-4ab5-a605-18f7e3c31c51",
   "metadata": {},
   "source": [
    "## 3. Model fitting and inverse problems\n",
    "\n",
    "The problem statement is an example of an **inverse problem**. The goal of an inverse problem is to estimate an unknown parameter that is not directly observable by using measured data and a mathematical model linking the observed and the unknown.\n",
    "\n",
    "Central to this process is **model fitting**, where a mathematical model is selected or designed to describe the relationship between observed data and the unknown parameter. This model is adjusted to minimise the disparity between predicted values and actual observations, typically employing optimisation techniques to find the best-fitting parameters. Through model fitting, predictions or estimations about the unknown parameter can be derived.\n",
    "\n",
    "#### Conventional methods\n",
    "\n",
    "Linear regression or optimisation techniques are typically employed to address inverse problems. Let us consider a scenario where we have a dataset comprising observed data points and a mathematical model that links these observations to the unknown parameter we aim to estimate. Linear regression, for instance, seeks to establish a linear relationship between the observed data and the unknown parameter. This involves minimising the squared differences between the observed data points and the corresponding predictions made by the model.\n",
    "\n",
    "However, traditional methods like linear regression have certain limitations when dealing with inverse problems:\n",
    "\n",
    "1. **Assumptions about linearity:** Linear regression assumes that the relationship between the observed data and the unknown parameter is linear. In many real-world scenarios, this assumption may not hold true, leading to biased estimates.\n",
    "\n",
    "2. **Overfitting:** Conventional methods may overfit the data, particularly when dealing with high-dimensional datasets or when the model is overly complex relative to the available data. Overfitting can result in poor generalisation performance and unreliable estimates of the unknown parameter.\n",
    "\n",
    "3. **Uncertainty quantification:** Linear regression typically does not provide a straightforward means to quantify uncertainty in the estimated parameters. It offers **point estimates** without adequately capturing the inherent uncertainty in the data or the model assumptions.\n",
    "\n",
    "#### Bayesian inference\n",
    "\n",
    "A Bayesian framework offers significant advantages. In Bayesian inference, we treat the unknown parameter as a random variable and specify a prior distribution representing our initial beliefs or knowledge about the parameter before observing the data. By combining this prior distribution with the likelihood function (which describes how the data are generated given the parameter values) and applying Bayes' theorem, we can derive the posterior distribution, reflecting our updated beliefs about the parameter after observing the data.\n",
    "\n",
    "There are multiple reasons why a Bayesian framework is better suited for solving inverse problems:\n",
    "\n",
    "1. **Incorporating prior knowledge:** Bayesian inference enables us to incorporate prior knowledge or beliefs about the unknown parameter into the estimation process. This proves particularly useful when dealing with limited data, as it helps regularise the estimation and reduces the risk of overfitting.\n",
    "\n",
    "2. **Flexibility in modelling:** Unlike traditional methods, which often rely on specific assumptions about the data-generating process (e.g. linearity in linear regression), Bayesian inference provides a flexible framework for modelling complex relationships and incorporating various sources of uncertainty.\n",
    "\n",
    "3. **Uncertainty quantification:** Bayesian inference naturally provides a means to quantify uncertainty in the estimated parameters through the posterior distribution. This allows for more informed decision-making by accounting for the inherent uncertainty in the data and the model.\n",
    "\n",
    "Overall, the Bayesian framework offers a principled approach to solving inverse problems by integrating prior knowledge, capturing uncertainty, and providing more robust and interpretable estimates compared to traditional methods like linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7115a",
   "metadata": {},
   "source": [
    "## 4. Generating synthetic data\n",
    "\n",
    "In order to introduce the Bayesian approach in the most intuitive manner, the experimental observations are generated numerically so that they deviate from the *true* constitutive model using a known noise model. This allows for a one-to-one comparison between the *true* parameter values and the inferred parameter distributions.\n",
    "\n",
    "The noise $\\Omega$ in the stress measurements has a normal distribution with a zero mean and a standard deviation of $s_{noise}$. Note that in this case, only the stress measurement is contaminated by noise. \n",
    "\n",
    "$$\\Omega = \\mathcal{N}(\\mu, \\sigma^2) = \\mathcal{N}(0, 0.01^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11b3428-0a96-4931-a583-73f3ff663f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(model, x, noise_std_dev, n_observations, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    x = np.random.choice(x, n_observations)\n",
    "    y = model.compute_stress(x)\n",
    "    noise = np.random.normal(loc=0, scale=noise_std_dev, size=len(y))\n",
    "    return x, y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eda3e5a-ef70-468f-8f0a-27e85fad4921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10ecd4d50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear = LinearElastic(210)\n",
    "x = np.linspace(0, 1.2e-3, 100)\n",
    "strain, stress = generate_synthetic_data(linear, x, 0.01, 10)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 3.5))\n",
    "plt.scatter(strain, stress, label='Observation')\n",
    "plt.title(\"Experimental observations\")\n",
    "plt.xlabel(\"Strain $\\epsilon$\")\n",
    "plt.ylabel(\"Stress $\\sigma$\")\n",
    "plt.legend()\n",
    "# plt.savefig(\"figures/linear-elastic-experimental-observations.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2b47c",
   "metadata": {},
   "source": [
    "## Constitutive model and *true* material parameters\n",
    "\n",
    "It is assumed that the behaviour of the material specimen can be described by a linear elastic law that is defined by a single parameter: Young's modulus $E$. The stress-strain response of the linear elastic model during uniaxial tension can be written as:\n",
    "\n",
    "$$\\sigma(\\epsilon, \\textbf{x}) = E\\epsilon$$\n",
    "\n",
    "where $\\sigma$ denotes the stress, $\\epsilon$ the strain, $\\textbf{x}$ the model parameter vector (here $\\textbf{x} = E$) and $E$ the Young's modulus. The *true* value of $E$ that we are attempting to identify (infer) from the experimental observations is:\n",
    "\n",
    "$$E = 210 \\; \\textrm{GPa}$$\n",
    "\n",
    "The *true* stress-strain response and the noisy experimental observations are illustrated in the following figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dc7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_model(E, epsilon):\n",
    "    \"\"\"\n",
    "    Linear-elastic material model - calculate\n",
    "    stress as a function of strain\n",
    "    \"\"\"\n",
    "    return E * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecbda677",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstress_strain_response(strain)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(strain_data, stress_data);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.stress_strain_response(strain)\n",
    "plt.scatter(strain_data, stress_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc6b00",
   "metadata": {},
   "source": [
    "## Bayesian inference\n",
    "\n",
    "We have some noisy experimental data from a uniaxial tensile test of a material specimen. Using our expert judgement we have hypothesised that the material response can be described by a linear-elastic material law. We now wish to identify (infer) the model parameters from the experimental observations. \n",
    "\n",
    "The most commonly used approach to identify model parameters is to formulate an error function that measures the difference between the model response and the experimental data. The error function is then minimised with respect to the model parameters in order to determine the most suitable values (linear regression etc). This approach provides a deterministic estimate of model parameters, and is unable to account for the unavoidable uncertainties associated with determining parameters from noisy experimental data.\n",
    "\n",
    "The Bayesian approach enables a rigorous treatment of all sources of uncertainy, for example, noise in the experimental observations and model uncertainty (uncertainty due to assumptions and simpliciations made in the physical model). The model and model parameters that explain an observed data set are treated as uncertain variables, as opposed to deterministic variables. Bayesian inference provides a framework to learn the entire distribution of model parameters, not just deterministic estimates, which maximize the probability of observing the given data. Learning comes from two sources: (1) the evidence provided by the observed data, and (2) domain knowledge from experts (i.e. prior knowledge).\n",
    "\n",
    "## Bayes' theorem\n",
    "\n",
    "Baye's theorem is used to determine the probability of a hypothesis given observed evidence (the posterior probability). In this example, we can think of the hypothesis and evidence as follows:\n",
    "\n",
    "- **Hypothesis:** we hypothesise a value for the model parameters and then we assess how well the model parameters explain the observations\n",
    "- **Evidence:** the evidence is in the form of experimental observations (stress-strain data from a uniaxial tensile test)\n",
    "\n",
    "The posterior probability is a function of the prior probability (prior knowledge) and a \"likelihood function\" derived from a statistical model for the observed data. Bayesian inference computes the posterior probability according to Bayes' theorem:\n",
    "\n",
    "$$\\pi(\\textbf{x}|\\textbf{y}) = \\frac{\\pi(\\textbf{x})\\pi(\\textbf{y}|\\textbf{x})}{\\pi(\\textbf{y})}$$\n",
    "\n",
    "where $\\pi(\\textbf{x}|\\textbf{y})$ is the posterior probability, $\\pi(\\textbf{x})$ is the prior probability, $\\pi(\\textbf{y}|\\textbf{x})$ is the likelihood and $\\textbf{x}$ denotes a vector with $n_p$ model parameters and $\\textbf{y}$ denotes a vector with $n_m$ observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c53ea",
   "metadata": {},
   "source": [
    "## Prior $\\pi(\\textbf{x})$\n",
    "\n",
    "The prior contains one's prior belief about the value of a parameter before evidence is taken into account. We can obtain a prior from the assessment of an expert or by consulting the literature (e.g. typical values of material stiffness $E$).\n",
    "\n",
    "The only unknown parameter is the material stiffness $E$ and we use a prior in the form of a modified normal distribution:\n",
    "\n",
    "$$\\pi(E) \\propto exp\\left(-\\frac{(E - \\overline{E})^2}{2s^2_E}\\right) \\quad \\text{if}\\; E \\geqslant 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_distribution(x, mean, std_dev):\n",
    "    return np.exp(-((x - mean) ** 2 / (2 * std_dev**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976327b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_prior(pi, mean, std_dev):\n",
    "    def wrapper(x):\n",
    "        return pi(x, mean, std_dev)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197fbeb",
   "metadata": {},
   "source": [
    "## Likelihood $\\pi(\\textbf{y}|\\textbf{x})$\n",
    "\n",
    "The likelihood function represents the probability that the observed data $\\textbf{y}$ was generated by the model parameters $\\textbf{x}$. Thus, when evaluated on a given sample of the model parameters $\\textbf{x}$, the likelihood function indicates which parameter values are more likely than others, in the sense that they would have made the observed data $\\textbf{y}$ more probable. A low value of likelihood would indicate that either the data is rare or the model/model parameters are wrong. To construct the likelihood function we need to define a model that represents the data-generating process.\n",
    "\n",
    "### Statistical generating model \n",
    "\n",
    "We define a statistical model that represents the data-generating process (i.e. a model of our experimental data).\n",
    "\n",
    "$$\\textbf{y} = \\textbf{f}(\\textbf{x}) + \\mathbf{\\Omega}$$\n",
    "\n",
    "where $\\textbf{y}$ denotes a vector with $n_m$ experimental observations, $\\textbf{x}$ denotes a vector with $n_p$ unknown model parameters, and $\\mathbf{\\Omega}$ is the noise in the experimental observations. We assume that the noise distribution is known (including its parameters). $\\textbf{f}(\\textbf{x})$ denotes the model and is a function of the unknown model parameters $\\textbf{x}$. For this case the only unknown parameter is the material stiffness $E$. The likelihood function is formulated as follows:\n",
    "\n",
    "$$\\pi(\\textbf{y}|\\textbf{x}) = \\pi_{noise}(\\textbf{y} - \\textbf{f}(\\textbf{x}))$$\n",
    "\n",
    "The only unknown material parameter in the linear elastic model is the Young's modulus ($E$) and based on the above, the additive noise model for a single stress measurement can be written as follows:\n",
    "\n",
    "$$y = E\\epsilon + \\Omega$$\n",
    "\n",
    "where $y$ denotes the measured stress and $\\Omega$ denotes the random variable representing the noise in the stress measurement. We consider the noise distribution to be normal (Gaussian) and hence, the likelihood function for a single observation can be expressed as:\n",
    "\n",
    "$$\\pi(y|E) = \\pi_{noise}(y - E\\epsilon) = \\frac{1}{s_{noise}\\sqrt{2\\pi}}exp\\left(-\\frac{1}{2}{\\frac{(y - E\\epsilon)^2}{s^2_{noise}}}\\right)$$\n",
    "\n",
    "The likelihood for all observations can be expressed as:\n",
    "\n",
    "$$\\pi(\\textbf{y}|E) = \\frac{1}{s_{noise}\\sqrt{2\\pi}}exp\\left(-\\frac{1}{2}{\\frac{\\sum_{i=1}^{n_m}(y - E\\epsilon)^2}{s^2_{noise}}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02325d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_distribution(omega, sigma):\n",
    "    return 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-0.5 * (omega**2 / sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_omega(observation, model):\n",
    "    return observation - model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_likelihood(pi, sigma, observations, x):\n",
    "    def wrapper(candidate):\n",
    "        omega = 0\n",
    "        for i in range(len(x)):\n",
    "            omega += calculate_omega(observations[i], material_model(candidate, x[i]))\n",
    "        return pi(omega, sigma)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e431499",
   "metadata": {},
   "source": [
    "## Posterior $\\pi(E|y)$\n",
    "\n",
    "The PDF of the unknown parameters $\\textbf{x}$, given the observations $\\textbf{y}$\n",
    "\n",
    "The posterior distribution for a single stress measurement reads:\n",
    "\n",
    "$$\\pi(\\textbf{x}|\\textbf{y}) \\propto \\pi(\\textbf{x})\\pi(\\textbf{y}|\\textbf{x})$$\n",
    "\n",
    "$$\\pi(E|y) \\propto exp\\left(-\\left[\\frac{(E - \\overline{E})^2}{2s^2_E} + \\frac{(y-E\\epsilon)^2} {2s^2_{noise}}\\right]\\right) \\quad \\text{if}\\; E \\geqslant 0$$\n",
    "\n",
    "Since the data $y$ is already measured, the denominator in Bayes' Theorem $\\pi(y)$ is a positive constant number $C$. This constant number can be regarded as a normalisation factor that ensures that the integral of the posterior $\\pi(E|y)$ over $E$ equals 1:\n",
    "\n",
    "$$\\pi(E|y) = \\frac{1}{C}\\pi(E)\\pi(y|E)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_posterior(prior, likelihood):\n",
    "    return prior * likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(calc_prior, calc_likelihood, parameter_candidates):\n",
    "    \"\"\"\n",
    "    Search every possible candidate\n",
    "    \"\"\"\n",
    "    pdf = []\n",
    "    for candidate in parameter_candidates:\n",
    "        pdf.append(calc_posterior(calc_prior(candidate), calc_likelihood(candidate)))\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0090add",
   "metadata": {},
   "source": [
    "## Analytical solution\n",
    "\n",
    "It is possible to analytically examine the posterior distribution for a linear elastic model if the noise model is additive and the noise distribution and the prior distribution are (modified) normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c0e0d",
   "metadata": {},
   "source": [
    "## Experimental stress-strain data - 2 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677544f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = random_draw(n_observations, 2)\n",
    "\n",
    "prior = set_prior(prior_distribution, 150, 50)\n",
    "likelihood = set_likelihood(\n",
    "    likelihood_distribution, 0.01, stress_data[subset], strain_data[subset]\n",
    ")\n",
    "candidate_parameter = np.linspace(0, 300, 1000)\n",
    "posterior = grid_search(prior, likelihood, candidate_parameter)\n",
    "\n",
    "[m, c] = linear_regression(strain_data[subset], stress_data[subset])\n",
    "\n",
    "plot_posterior(candidate_parameter, prior, posterior, E, m)\n",
    "add_labels(\"Posterior distribution - 2 observations\", \"E\", \"$\\pi$\")\n",
    "\n",
    "plot_regression_results(strain, E, m, c)\n",
    "plt.scatter(strain_data, stress_data, alpha=0.25)\n",
    "plt.scatter(strain_data[subset], stress_data[subset], color=\"C2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba32056",
   "metadata": {},
   "source": [
    "## Experimental stress-strain data - 10 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = set_prior(prior_distribution, 150, 50)\n",
    "likelihood = set_likelihood(likelihood_distribution, 0.01, stress_data, strain_data)\n",
    "candidate_parameter = np.linspace(0, 300, 1000)\n",
    "posterior = grid_search(prior, likelihood, candidate_parameter)\n",
    "\n",
    "[m, c] = linear_regression(strain_data, stress_data)\n",
    "\n",
    "plot_posterior(candidate_parameter, prior, posterior, E, m)\n",
    "add_labels(\"Posterior distribution - 10 observations\", \"E\", \"$\\pi$\")\n",
    "\n",
    "plot_regression_results(strain, E, m, c)\n",
    "plt.scatter(strain_data, stress_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c992336",
   "metadata": {},
   "source": [
    "## Maximum a posteriori probability (MAP) estimate\n",
    "\n",
    "Calculate the maximum a posteriori probability (MAP) point - the point at which the posterior distribution is (globally) maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_map_point(x, pdf, burn=0):\n",
    "    x_burned = x[burn:]\n",
    "    pdf_burned = pdf[burn:]\n",
    "    return x_burned[np.argmax(pdf_burned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_point = estimate_map_point(candidate_parameter, posterior)\n",
    "print(\"The estimated MAP point is {:.2f} GPa\".format(map_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35fe67",
   "metadata": {},
   "source": [
    "## 95% credible region\n",
    "\n",
    "The 95% credible region is the region that contains 95% of the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f214f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_credible_interval(posterior, interval=0.95):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbee1ce",
   "metadata": {},
   "source": [
    "## 95% prediction interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c847a",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings\n",
    "\n",
    "Once the posterior is constructed, it needs to be analysed to determine the statistical summaries. For the linear elastic case, the statistical summaries were establised analytically and by employing a grid search method (i.e.  exhaustively searching through a specified subset of the parameter space).\n",
    "\n",
    "When the search space becomes larger, or the model is expensive to evaluate, it can become infeasible to do an exhaustive search and we must turn to randomised searches (Monte Carlo methods etc). There are many libraries for searching the posterior but we will implement a [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) sampler to help develop undersanding. Note that I stole the code for the sampler from this [blog](https://colindcarroll.com/2018/11/24/animated-mcmc-with-matplotlib/) by Colin Carroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_sampler(pi, steps=3000, step_size=5, init=0):\n",
    "    \"\"\"\n",
    "    Metropolis-Hastings sampler with a normal proposal\n",
    "    \"\"\"\n",
    "    point = init\n",
    "    samples = []\n",
    "    pdf = []\n",
    "    for _ in range(int(steps)):\n",
    "        proposal = np.random.normal(point, step_size)\n",
    "        if np.random.rand() < pi(proposal) / pi(point):\n",
    "            point = proposal\n",
    "        samples.append(point)\n",
    "        pdf.append(pi(point))\n",
    "    return np.array(samples), np.array(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9719f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_posterior(calc_prior, calc_likelihood, observations, x):\n",
    "    def wrapper(candidate):\n",
    "        return calc_posterior(calc_prior(candidate), calc_likelihood(candidate))\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = set_prior(prior_distribution, 150, 50)\n",
    "likelihood = set_likelihood(likelihood_distribution, 0.01, stress_data, strain_data)\n",
    "\n",
    "samples, pdf = mh_sampler(\n",
    "    set_posterior(prior, likelihood, stress_data, strain_data),\n",
    "    steps=1e5,\n",
    "    step_size=2.5,\n",
    "    init=150,\n",
    ")\n",
    "plt.plot(samples)\n",
    "plt.axhline(E, ls=\"--\", color=\"dimgray\")\n",
    "add_labels(\"Chain\", \"Sample\", \"E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f03036",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(samples[1000:], pdf[1000:])\n",
    "plt.axvline(E, ls=\"--\", color=\"dimgray\")\n",
    "add_labels(\"Posterior distribution\", \"E\", \"$\\pi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_point = estimate_map_point(samples, pdf, burn=0)\n",
    "print(\"The estimated MAP point is {:.2f} GPa\".format(map_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0fd6b",
   "metadata": {},
   "source": [
    "## Adaptive Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [strain_data, stress_data]\n",
    "model.set_prior(150, 50)\n",
    "mh = AdaptiveMetropolisHastings(model, data, n_samples=1e5)\n",
    "\n",
    "x_0 = np.array([150])  # Initial sample\n",
    "x_hist, pdf_hist, accept_rate = mh.sample(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cdcb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_candidate = np.array([210])\n",
    "print(model.posterior(strain_data, stress_data, x_candidate))\n",
    "\n",
    "pi = set_posterior(prior, likelihood, stress_data, strain_data)\n",
    "print(pi(210))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81937935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot of the Markov chain values - use kernel density estimation or marginal distribution? Look at Seaborn?\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax1.scatter(x_hist[1000:], pdf_hist[1000:])\n",
    "ax1.axvline(E, ls=\"--\", color=\"dimgray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcdd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, sharex=True, figsize=(7.5, 3))\n",
    "ax1.plot(x_hist)\n",
    "ax1.axhline(E, ls=\"--\", color=\"dimgray\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
